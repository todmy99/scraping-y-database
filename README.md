ğŸ“š Web Scraping de Books to Scrape

Este proyecto realiza web scraping sobre Books to Scrape
 para obtener informaciÃ³n de libros (tÃ­tulo, precio, rating y categorÃ­a).
Luego, con la Google Books API, se buscan los autores y se guardan todos los datos en una base de datos SQLite.

âš™ï¸ TecnologÃ­as

```- Python 3
- BeautifulSoup4
- Requests
- Pandas
- SQLite3
- Google Books API
```

ğŸ—‚ï¸ Estructura del proyecto
```
ğŸ“ proyecto_libros/
â”‚
â”œâ”€â”€ books_scraping.ipynb   # Notebook principal del proyecto
â”œâ”€â”€ books.db                # Base de datos SQLite con los libros y autores
â”œâ”€â”€ .env                    # Archivo con la API Key
â””â”€â”€ README.md               # Este archivo
```

ğŸ” Variables de entorno
Crea un archivo .env con tu clave de Google Books API:
```
API_KEY=tu_clave_aqui
```

ğŸ§  Flujo del proyecto
```
1. Se realiza scraping del sitio Books to Scrape para obtener todas las categorÃ­as y libros.
2. Se limpian y formatean los datos (precios, ratings, etc.).
3. Se buscan los autores mediante la Google Books API.
4. Se guardan los datos en una base de datos SQLite, con tres tablas:
  - Libros
  - Autores
  - Libros_Autores (tabla intermedia para relaciones muchos a muchos)
5. Se realizan consultas SQL y pruebas con Ã­ndices para optimizar bÃºsquedas.
```

ğŸ§¾ Ejemplo de consulta SQL
```
SELECT L.titulo, A.nombre AS autor, L.precio
FROM Libros L
JOIN Libros_Autores LA ON L.id = LA.libro_id
JOIN Autores A ON A.id = LA.autor_id
WHERE L.precio < 25 AND L.rating >= 3
ORDER BY L.precio ASC;
```

ğŸš€ EjecuciÃ³n

- AbrÃ­ el archivo .ipynb en Jupyter Notebook o VS Code.
- EjecutÃ¡ las celdas en orden.
- VerificÃ¡ los resultados en la base de datos o con las consultas SQL.
